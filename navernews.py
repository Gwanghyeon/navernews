import requests, sys
from bs4 import BeautifulSoup
from pprint import pprint
import re, sys
from datetime import datetime
from articleBody import getArticleBody

result = requests.get('https://news.naver.com/main/home.nhn')
src = result.content
soup = BeautifulSoup(src, 'lxml')
d = datetime.now()

class News:

    base_url = 'https://news.naver.com/'
    section = ['pol', 'eco', 'soc', 'lif', 'wor', 'sci']
    sectionName = ['ì •ì¹˜', 'ê²½ì œ', 'ì‚¬íšŒ', 'ìƒí™œ/ë¬¸í™”', 'ì„¸ê³„', 'IT/ê³¼í•™']
    timeFormat = d.strftime("%mì›”%dì¼ %I:%M %p")

    def politics(self):
        base_url = self.base_url
        section = self.section
        sectionName = self.sectionName
        timeFormat = self.timeFormat
        tag_all = soup.find_all(class_=re.compile("rig.rank"+section[0]))
        newsUrls = []
        print("\nê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤:"+sectionName[0], timeFormat)
        for i, headline in enumerate(tag_all, start=1):
            url = self.base_url + headline.attrs['href']
            title = headline.text
            print(f'{i} | {title}\n{url}')
            newsUrls.append(url)
        try:
            choice = int(input('\nì½ê³  ì‹¶ìœ¼ì‹  ê¸°ì‚¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ')) - 1
        except ValueError:
            sys.exit()
        print()
        print(f'{choice + 1}| {tag_all[choice].text}')
        url = newsUrls[choice]
        getArticleBody(url)

    def economy(self):
        base_url = self.base_url
        section = self.section
        sectionName = self.sectionName
        timeFormat = self.timeFormat
        tag_all = soup.find_all(class_=re.compile("rig.rank"+section[1]))
        newsUrls = []
        print("\nê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤:"+sectionName[1], timeFormat)
        for i, headline in enumerate(tag_all, start=1):
            url = self.base_url + headline.attrs['href']
            title = headline.text
            print(f'{i} | {title}\n{url}')
            newsUrls.append(url)
        try:
            choice = int(input('\nì½ê³  ì‹¶ìœ¼ì‹  ê¸°ì‚¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ')) - 1
        except ValueError:
            sys.exit()
        print()
        print(f'{choice + 1}| {tag_all[choice].text}')
        url = newsUrls[choice]
        getArticleBody(url)

    def society(self):
        base_url = self.base_url
        section = self.section
        sectionName = self.sectionName
        timeFormat = self.timeFormat
        tag_all = soup.find_all(class_=re.compile("rig.rank"+section[2]))
        newsUrls = []
        print("\nê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤:"+sectionName[2], timeFormat)
        for i, headline in enumerate(tag_all, start=1):
            url = self.base_url + headline.attrs['href']
            title = headline.text
            print(f'{i} | {title}\n{url}')
            newsUrls.append(url)
        try:
            choice = int(input('\nì½ê³  ì‹¶ìœ¼ì‹  ê¸°ì‚¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ')) - 1
        except ValueError:
            sys.exit()

        print()
        print(f'{choice + 1}| {tag_all[choice].text}')
        url = newsUrls[choice]
        getArticleBody(url)

    def life(self):
        base_url = self.base_url
        section = self.section
        sectionName = self.sectionName
        timeFormat = self.timeFormat
        tag_all = soup.find_all(class_=re.compile("rig.rank"+section[3]))
        newsUrls = []
        print("\nê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤:"+sectionName[3], timeFormat)
        for i, headline in enumerate(tag_all, start=1):
            url = self.base_url + headline.attrs['href']
            title = headline.text
            print(f'{i} | {title}\n{url}')
            newsUrls.append(url)
        try:
            choice = int(input('\nì½ê³  ì‹¶ìœ¼ì‹  ê¸°ì‚¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ')) - 1
        except ValueError:
            sys.exit()

        print()
        print(f'{choice + 1}| {tag_all[choice].text}')
        url = newsUrls[choice]
        getArticleBody(url)

    def world(self):
        base_url = self.base_url
        section = self.section
        sectionName = self.sectionName
        timeFormat = self.timeFormat
        tag_all = soup.find_all(class_=re.compile("rig.rank"+section[4]))
        newsUrls = []
        print("\nê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤:"+sectionName[4], timeFormat)
        for i, headline in enumerate(tag_all, start=1):
            url = self.base_url + headline.attrs['href']
            title = headline.text
            print(f'{i} | {title}\n{url}')
            newsUrls.append(url)
        try:
            choice = int(input('\nì½ê³  ì‹¶ìœ¼ì‹  ê¸°ì‚¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ')) - 1
        except ValueError:
            sys.exit()
        print()
        print(f'{choice + 1}| {tag_all[choice].text}')
        url = newsUrls[choice]
        getArticleBody(url)

    def science(self):
        base_url = self.base_url
        section = self.section
        sectionName = self.sectionName
        timeFormat = self.timeFormat
        tag_all = soup.find_all(class_=re.compile("rig.rank"+section[5]))
        newsUrls = []
        print("\nê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤:"+sectionName[5], timeFormat)
        for i, headline in enumerate(tag_all, start=1):
            url = self.base_url + headline.attrs['href']
            title = headline.text
            print(f'{i} | {title}\n{url}')
            newsUrls.append(url)
        try:
            choice = int(input('\nì½ê³  ì‹¶ìœ¼ì‹  ê¸°ì‚¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ')) - 1
        except ValueError:
            sys.exit()
        print()
        print(f'{choice + 1}| {tag_all[choice].text}')
        url = newsUrls[choice]
        getArticleBody(url)

news = News()
sectionNumDict = {1: news.politics, 2: news.economy, 3: news.society, 4: news.life, 5: news.world, 6: news.science}

try:
    newsType=int(input("ë³´ê³ ì‹¶ì€ ë‰´ìŠ¤ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:\n1:ì •ì¹˜\n2:ê²½ì œ\n3:ì‚¬íšŒ\n4:ìƒí™œ/ë¬¸í™”\n5:ì„¸ê³„\n6:IT/ê³¼í•™\nğŸ‘‰ "))
except ValueError:
    print("1ë¶€í„° 6ê¹Œì§€ ìˆ«ìë§Œ ëˆŒëŸ¬ì£¼ì„¸ìš”")
    sys.exit()

sectionNumDict[newsType]()

